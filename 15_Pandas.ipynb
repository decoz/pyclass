{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15 Pandas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsyuiJWziuFgyx/Grx7iBy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decoz/pyclass/blob/master/15_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk77f_z1FVuy"
      },
      "source": [
        "# 15 Pandas \n",
        "\n",
        "Numpy 가 list 를 수치적 목적에 맞게 보강한 거라면 pandas 는 dictionay 를 보다 더 자료의 저장과 처리에 맞게 보강한 라이브러리입니다.  일반적으로 저희가 엑셀같은 표 형식으로 저장하는 데이터를 다룹니다. \n",
        "\n",
        "주료 자료 검색, 변경, 저장에 특화되어 있으며 홈페이지나 사무용 소프트웨어같은 방대한 자료를 간편히 다룰 때도 사용되지만 과학적인 데이터등을 저장할때도 이런 표 형태로 저장되는 경우가 많습니다. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVna3lIrEIxm"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAhUrPmpF4Si"
      },
      "source": [
        "## 15.1 DataFrame\n",
        "\n",
        "학생들의 정보를 저장하는 데이터를 생성한다고 가정해보겠습니다. 다음은 간단하게 이름과 학번, 나이가 따로 저장된 리스트를 딕셔너리로 묶어서 저장하는 방식입니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULBnfU0GGZFe"
      },
      "source": [
        "name = ['jhon', 'smith', 'dow'] \n",
        "stu_no = ['20210001', '20210002', '20210003']\n",
        "age = [25, 22, 21]\n",
        "\n",
        "stu_dicts = {\n",
        "  'name': name,\n",
        "  'stu_no' : stu_no,\n",
        "  \"age\" : age\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLEcoDnjGmO2"
      },
      "source": [
        "물론 이런식으로 저장을 해도 관리가 불가능한 것은 아니지만 실수로 리스트에 조금만 누락이 발생하도 누구의 데이터인지 연관시키기가 어렵습니다. 더 나은 방법은 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytAR_8yCH7qU"
      },
      "source": [
        "stu1 = {'name':'jhon', 'stu_no':'20210001', 'age':25}\n",
        "stu2 = {'name':'smith', 'stu_no':'20210002', 'age':22}\n",
        "stu3 = {'name':'dow', 'stu_no':'20210003', 'age':21}\n",
        "\n",
        "stu_list = [stu1, stu2, stu3]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqresL8qIcK1"
      },
      "source": [
        "이런식으로 관리를 하는 것일겁니다.  하지만 이런 자료를 다루는 일들은 대부분 단순하지만 작업의 종류가 많은 경우가 많습니다. 그때마다 매번 데이터를 다룰때 이런식으로 dictionay 를 만들어 저장하고 또 필요한 데이터를 찾고 하는 일은 상당히 피곤한 일입니다. \n",
        "\n",
        "이런 걸 단순화하기 위한 구조로 pandas 는 일종의 표형식 자료인 DataFrame 을 제공합니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhPTnjRwIbBJ"
      },
      "source": [
        "df = pd.DataFrame( { 'A':[1,2], 'B':[3,4]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssael6mOLiuo"
      },
      "source": [
        "보시면 DataFrame에 딕셔너리를 넣으면 데이터 프레임을 얻을 수 있음을 알 수 있습니다.  그러면 위에 stu_dicts 를 넣어서 생성해 보도록 하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bnne85sLyj6"
      },
      "source": [
        "stu_df = pd.DataFrame(stu_dicts)\n",
        "stu_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zr0Z5C1Nv-N"
      },
      "source": [
        " \n",
        " 두번째 방법으로 자료를 관리한다면 DataFrame.from_records 이용해서 변경가능합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX10XsHfMTyc"
      },
      "source": [
        "stu_df = pd.DataFrame.from_records(stu_list)\n",
        "stu_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2ehZTZwMNi8"
      },
      "source": [
        "이렇게 만든 데이터 프레임은 다시 dict 로 바꿀 수도 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaYoAXqDJqoa"
      },
      "source": [
        "stu_df.to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtADOcni7ifD"
      },
      "source": [
        "\n",
        "DataFrame 을 만드는 또 하나의 방법은 데이터와 항목명을 따로 입력하는 겁니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDdbyuF27vAu"
      },
      "source": [
        "df = pd.DataFrame([[1,4], [2,5], [3,6]], columns = ['A','B'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx9r1g3l630S"
      },
      "source": [
        "## 15.2 DataFrame 칼럼\n",
        "\n",
        "위와 같은 표 형태의 데이터에서 name, age 등의 특정 항목을 칼럼(column) 이라고 합니다. pandas 는 이러한 컬럼단위로 값을 가져오거나 추가, 지우거나 할 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dEjkfv58AwD"
      },
      "source": [
        "### 특정 칼럼 가져오기 \n",
        "\n",
        "dataframe 은 Numy 같은 배열처럼 [] 를 통해 억세스를 지원합니다. 다만 그 안에는 인덱스 번호가 아니라 칼럼 명을 넣어서 칼럼데이터를 Series라는 배열형태로 가져옵니다. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw9Hc6E58QGK"
      },
      "source": [
        "print( stu_df['name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBRdHypsLc1V"
      },
      "source": [
        "특이한 것은 칼럼을 클래스의 변수처럼 '.항목명' 형태로도 호출이 된다는 점입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlPqCWkh8SGa"
      },
      "source": [
        "print( stu_df.age )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znrbtV23Lqr2"
      },
      "source": [
        "가져온 series 값은 배열처럼 인덱스에 0,1,2.. 형태로 개별 값을 억세스 할 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81yy98Jv8b8q"
      },
      "source": [
        "print( stu_df['name'][0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w2-to1pL1pp"
      },
      "source": [
        "참고로 .colmuns 라는 멤버 변수를 통해 모든 칼럼이름을 배열로 받아 올 수도 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkwzxAeDESN6"
      },
      "source": [
        "stu_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJqXEsYTMOgY"
      },
      "source": [
        "또한 [] 안에 다시 [칼럼1, 칼럼2]  라는 배열형태로 억세스를 하면 여러 칼럼을 가진 데이터만 억세스할 수도 있죠 단 이렇게 억세스를 하면 series 가 아닌 dataframe 타입으로 리턴됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVUHm-GrMHtf"
      },
      "source": [
        "stu_df[['name', 'age']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q64xFuzhCbRH"
      },
      "source": [
        "### 칼럼 추가 \n",
        "\n",
        "새로운 컬럼을 다음과 같이 추가할 수도 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmB77XLbCdvM"
      },
      "source": [
        "stu_df['sex'] = ['male','male', 'female']\n",
        "stu_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKeWlkCCGVEI"
      },
      "source": [
        "### 칼럼 삭제\n",
        "\n",
        "특정 칼럼을 삭제하는 방법은 약간 복잡한데 drop 이라는 명령을 사용합니다. 이때 드롭할 칼럼명들을 배열로 입력하고  뒤에 axis = 1 이라는 추가인자로 칼럼 단위로 드롭함을 명시합니다.  inplace = True 는 삭제가 원 데이터에 반영됨을 확정해줍니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtHhHy1EE4r0"
      },
      "source": [
        "stu_df.drop(['sex'], axis = 1, inplace = True)\n",
        "stu_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OskUilXQIrUn"
      },
      "source": [
        "## 15.3 DataFrame 레코드\n",
        "\n",
        "위에서 언급한 칼럼이 특정 항목의 값들을 모은 데이터라면 여러 항목값을 가진 가로줄은 하나의 개체를 의미합니다. 이런 하나의 개체를 컴퓨터에선 흔히 레코드라고 합니다.  하지만 종종 칼럼(column) 과 대비해 로우(row)라고 불리기도 합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdYqFXwe995Z"
      },
      "source": [
        "### 부분 레코드 가져오기 \n",
        "\n",
        "위와 같은 표에서 일부 학생들의 데이터를 억세스 할 수도 있습니다. stu_df 에서 한 줄은 한 학생의 데이터를 의미합니다.  이렇게 여러개의 항목값을 가진 하나의 데이터를 레코드라고 합니다. \n",
        "\n",
        "pandas 에서는 전체 레코드에서 몇몇 부분 레코드를 억세스할 수 있는 몇몇 방법을 제공합니다. \n",
        "\n",
        "- head(n) : 위에서 n 개의 레코드를 가져옴\n",
        "- tail(n) : 아래에서 n 개의 레코드를 가져옴\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nokIZIg18o2Q"
      },
      "source": [
        "stu_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzG8wO3wBzJ2"
      },
      "source": [
        "stu_df.tail(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnYlw_3uB4wN"
      },
      "source": [
        "\n",
        "하지만 더 범용적인 방법은 Numpy 와 유사한 슬라이싱도 지원합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdKjZ60iB3al"
      },
      "source": [
        "stu_df[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNH_I5UdJgbn"
      },
      "source": [
        "만일 n번째(0부터 시작) 레코드만 억세스 하고 싶다면 [n:n+1] 이라고 해주면 됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85JDHdVSKA86"
      },
      "source": [
        "stu_df[1:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdTBZsldNSqi"
      },
      "source": [
        "레코드와 칼럼 억세스는 서로 병합이 가능합니다. 만일 처음 두 레코드의 name 과 stu_no 만 뽑아내고 싶다면 다음과 같이 조합해서 쓸 수도 있죠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kxkx7gONgYr"
      },
      "source": [
        "stu_df[:2][['name','stu_no']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3cxQk7ETebB"
      },
      "source": [
        "### 레코드 추가 \n",
        "\n",
        "특정 레코드를 추가할땐 append 를 사용합니다.  \n",
        "```\n",
        "df1.append(df2)  # df1 에 df2 의 데이터를 추가\n",
        "```\n",
        "단 주의하실 것은 append 는 두 데이터프레임을 합한 값을 만들어주지만 자동으로 업데이트해주진 안습니다. 그래서 더 정확히는 \n",
        "```\n",
        "df1 = df1.append(df2)\n",
        "```\n",
        "이런식으로 두 데이터를 합친 후에 다시 저장을 해줘야 합니다. 그러면 간단한 예를 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRC6sL0rTl74"
      },
      "source": [
        "df = pd.DataFrame({'name':['jane'], 'stu_no':['20210004'], 'age':[23], 'sex':['female']})\n",
        "stu_df = stu_df.append(df)\n",
        "stu_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW2dkXxAM9d8"
      },
      "source": [
        "## 15.4 데이터 검색\n",
        "pandas 에서 가장 중요한 기능중에 하나는 조건에 의한 데이터 검색입니다. dataframe 의 주 목적이라고 해도 과언이 아닐 정도로 이런 테이블 형식의 데이터는 다양한 조건을 지원합니다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktgI-MLYQ-_g"
      },
      "source": [
        "\n",
        "### True, False 인덱싱 \n",
        "\n",
        "pandas 가 조건을 다루는 방식을 이해하기 위해서는 dataframe 의 [] 안에 들어가는 또 하나의 억세스 방법을 이해하셔야 합니다. 특정 레코드를 억세스하기 위해 그 안에 True 나 False 로 된 배열을 입력할 수 있습니다. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7iI6mmWQ00x"
      },
      "source": [
        "stu_df[[True, False, False, True]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKZJWW-ZRGkw"
      },
      "source": [
        "원래 stu_df 는 3개의 레코드를 갖고 있지만 위에서는 인덱스가 True로 지정된 것만 억세스해온 것을 알 수 있습니다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dtIZvK3SnA3"
      },
      "source": [
        "\n",
        "이번에는 특정 항목의 Series 를 뽑아서 조건을 붙여보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJcEsXKkRZR-"
      },
      "source": [
        "stu_df['age'] > 22 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOqaMcKuRTd4"
      },
      "source": [
        "stu_df['age'] 라는 series 배열이 조건문에 의해 각각 참과 거짓으로 바뀐 걸 보실 수 있습니다.  그렇다면 이걸 조합하면 다음과 같이 쓸 수 있습니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stk-qZ8MSXN2"
      },
      "source": [
        "stu_df[ stu_df['age'] > 22 ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP9TJyT7Rgxp"
      },
      "source": [
        "이것이 pandas 에서 다양한 조건문을 사용할 수 있는 원리입니다. 이번에는 이 조건문을 이용해서 jhon 의 나이를 출력해보도록 하겠습니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8D2GyPPCFum"
      },
      "source": [
        "stu_df[ stu_df['name'] == 'jhon'].age[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FELEhmh0ZbfV"
      },
      "source": [
        "두개의 조건을 동시에 줄 수도 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvIGAuTSTJGw"
      },
      "source": [
        "stu_df[ ( stu_df['age'] > 22 ) | ( stu_df['sex'] == 'female' ) ] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPQvmIy8aE3b"
      },
      "source": [
        "## 15.5 CSV 파일\n",
        "\n",
        "데이터를 파일로 저장하고 읽어오는 가장 쉬운 방법은 csv 파일을 사용하는 겁니다. 이는 엑셀에서도 읽히기 때문에 응용범위가 넓습니다.  csv 파일은 사실 데이터를 ',' 로 구분해 둔 텍스트 파일입니다. 하지만 간편하기 때문에 널리 사용됩니다. \n",
        "\n",
        "데이터를 csv 파일로 저장하는 방법은 매우 간단합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct_pzir2ZoPX"
      },
      "source": [
        "stu_df.to_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QPtegHyb8Pl"
      },
      "source": [
        "colab  좌측의 파일 메뉴를 열어서 보면 test.csv 파일이 보일 겁니다.  다은로드 받아서 더블클릭하면 엑셀이 설치된 컴퓨터라면 엑셀로 보실 수도 있을겁니다.\n",
        "\n",
        "그래도 그 내용을 직접 확인해보도록 하지요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESEeWoXBaunm"
      },
      "source": [
        "f = open('test.csv')\n",
        "print( f.read() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGXS0Fdca4z"
      },
      "source": [
        "의외로 심플하게 저장된 걸 보실수 있습니다. \n",
        "\n",
        " 이제 이 파일을 읽어서 df 에 저장해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZC9i2UHbtxs"
      },
      "source": [
        "df = pd.read_csv('test.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dmQ8LeEtMJZ"
      },
      "source": [
        "df.drop( [df.columns[0]], axis = 1, inplace = True )\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMmxvt-Edab1"
      },
      "source": [
        "실제로 과학 데이터는 csv 파일 형태로 웹에 제공되는 경우가 많습니다.   파이썬의 멋진 점은 굳이 이 파일을 다운로드 받아서 다시 읽지 안고 바로 url 로 억세스가 된다는 점입니다. \n",
        "\n",
        "다음은 uc 어바인 대학에서 제공하는 머신러닝을 위한 콘크리트 관련 데이터 입니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOJ5pBtkbyZt"
      },
      "source": [
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB1kN-CFfAc7"
      },
      "source": [
        "## 15.6 Numpy 변환 \n",
        "\n",
        "위에서 읽어들인 과학데이터를 이용하기 위해서는 가장 손쉬운 방법은 Numpy 로 변환하는 것입니다. 이는 dataframe 에 values 라는 변수값을 통해 쉽게 얻을 수 있습니다. \n",
        "\n",
        "다음은 위 데이터의 첫 레코드를 ndarray 로 변환한 것입니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxW_SDnQd3kK"
      },
      "source": [
        "print( df.head(1).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM6mS1htfz1O"
      },
      "source": [
        "특정 칼럼의 데이터를 Numpy배열로 얻고 싶으시면 다음과 같이 하시면 됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umRKiOf6foAF"
      },
      "source": [
        "df['Slag'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVDZacQ4gF2L"
      },
      "source": [
        "그러면 Coarse Aggr 이라는 항목을 한번 그래프로 표시해보도록 하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r0ngt7jgCG3"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "plt.plot( df['Coarse Aggr.'].values )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqDzY6q2gZSm"
      },
      "source": [
        "옆의 'Fine Aggr.' 과 비교해도 좋을 것 같네요 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hic8dV1IgPtS"
      },
      "source": [
        "plt.plot( df['Coarse Aggr.'].values , label = 'Coarse' )\n",
        "plt.plot( df['Fine Aggr.'].values , label = 'Fine' )\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbBGJzrpguD5"
      },
      "source": [
        "과학 라이브러리에서 pandas 의 역할은 이렇게 데이터를 간편히 저장하고  읽어서 여러 라이브러리에 응용하는 것입니다.  위에서는 따로 보여드리지 안았지만 특정 조건으로 데이터의 범위를 좁혀서 처리하면 더욱 많은 일을 할 수 있겠죠. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR_72FVtZWQ1"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : 실제 데이터 그려보기 \n",
        "위에서는 모든 Coarse Aggr 과 Fine Aggr 의 그래프를 그려보았습니다. 그러면 이번에는 다음과 같은 데이터의 그래프를 그려보세요 \n",
        "</font>\n",
        "\n",
        "```\n",
        "SP 가 9이상인 데이터의 \tSLUMP(cm) 와 FLOW(cm)\t수치를 그래프로 비교해보세요\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFwEbh5ZWQ1"
      },
      "source": [
        "## 연습문제의 코드를 작성하세요\n",
        "plt.plot( df[ df['SP'] >= 9 ]['SLUMP(cm)'].values , label = 'Slump')\n",
        "plt.plot( df[ df['SP'] >= 9 ]['FLOW(cm)'].values , label = 'Flow')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2XkjAt6vGrz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}